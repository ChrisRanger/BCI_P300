{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import mne\n",
    "import mnelab\n",
    "import numpy\n",
    "import matplotlib\n",
    "import xgboost\n",
    "import pyriemann\n",
    "import scipy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FeatureExtract # 自己提取时域频域特征的方法实现\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列标识符,P300二分类转字符36分类用\n",
    "chars = {'A': (1, 7), 'B': (1, 8), 'C': (1, 9), 'D': (1, 10), 'E': (1, 11), 'F': (1, 12), \n",
    "         'G': (2, 7), 'H': (2, 8), 'I': (2, 9), 'J': (2, 10), 'K': (2, 11), 'L': (2, 12), \n",
    "         'M': (3, 7), 'N': (3, 8), 'O': (3, 9), 'P': (3, 10), 'Q': (3, 11), 'R': (3, 12), \n",
    "         'S': (4, 7), 'T': (4, 8), 'U': (4, 9), 'V': (4, 10), 'W': (4, 11), 'X': (4, 12), \n",
    "         'Y': (5, 7), 'Z': (5, 8), '1': (5, 9), '2': (5, 10), '3': (5, 11), '4': (5, 12), \n",
    "         '5': (6, 7), '6': (6, 8), '7': (6, 9), '8': (6, 10), '9': (6, 11), '0': (6, 12), \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 313)\n"
     ]
    }
   ],
   "source": [
    "# 根据普适最优通道组合做特征工程处理原始数据集，转换为检测P300的二分类数据集\n",
    "# 执行五次转换五个被试者数据集\n",
    "optimal_channels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] #最优通道序号\n",
    "\n",
    "# 加载原始训练集\n",
    "raw_data = openpyxl.load_workbook(u'/home/chris/predict_code/lyft/bci/data/S5/S5_train_data.xlsx')\n",
    "raw_event = openpyxl.load_workbook(u'/home/chris/predict_code/lyft/bci/data/S5/S5_train_event.xlsx')\n",
    "\n",
    "# 加载测试集\n",
    "test_data = openpyxl.load_workbook(u'/home/chris/predict_code/lyft/bci/data/S1/S1_test_data.xlsx')\n",
    "test_event = openpyxl.load_workbook(u'/home/chris/predict_code/lyft/bci/data/S1/S1_test_event.xlsx')\n",
    "\n",
    "# 脑电数据集转换为P300二分类数据集，含剔除非优通道、数据预处理、滤波、特征提取等\n",
    "classify_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "# 带通滤波器上下界\n",
    "freq_min, freq_max = 1, 30\n",
    "# 调用8阶巴特沃斯带通滤波器\n",
    "# b, a = scipy.signal.butter(8, [0.02,0.8], 'bandpass')\n",
    "\n",
    "训练集\n",
    "for sheet in raw_event.sheetnames:\n",
    "    # 当前字符\n",
    "    current_char = sheet[7]\n",
    "    # print(current_char)\n",
    "    table_event = raw_event[sheet]\n",
    "    table_data = raw_data[sheet]\n",
    "    # 剔除bad通道电压值\n",
    "    for col_num in range(20):\n",
    "        if col_num+1 in optimal_channels:\n",
    "            pass\n",
    "        else:\n",
    "            table_data.delete_cols(col_num+1)\n",
    "            # print('delete ',col_num+1,' colum')\n",
    "    for row in range(raw_event[sheet].max_row):\n",
    "        if table_event.cell(row+1, 1).value >= 1 and table_event.cell(row+1, 1).value <= 12:\n",
    "            # data.shape: 275,-100ms~1000ms时间窗口20个电压的均值\n",
    "            # feature: 26\n",
    "            feature = []\n",
    "            data = []\n",
    "            for i in range(len(optimal_channels)):\n",
    "                channel = []\n",
    "                for j in range(275):\n",
    "                    channel.append(table_data.cell(table_event.cell(row+1, 2).value-24+j, i+1).value)\n",
    "                data.append(channel)\n",
    "                # 带通滤波\n",
    "                # filter_data = scipy.signal.filtfilt(b, a, data[][i])\n",
    "                filter_data = data[i]\n",
    "                # 16个时域特征\n",
    "                feature.append(FeatureExtract.mean_fea(filter_data))\n",
    "                feature.append(FeatureExtract.rms_fea(filter_data))\n",
    "                feature.append(FeatureExtract.sr_fea(filter_data))\n",
    "                feature.append(FeatureExtract.am_fea(filter_data))\n",
    "                feature.append(FeatureExtract.skew_fea(filter_data))\n",
    "                feature.append(FeatureExtract.kurt_fea(filter_data))\n",
    "                feature.append(FeatureExtract.max_fea(filter_data))\n",
    "                feature.append(FeatureExtract.min_fea(filter_data))\n",
    "                feature.append(FeatureExtract.pp_fea(filter_data))\n",
    "                feature.append(FeatureExtract.var_fea(filter_data))\n",
    "                feature.append(FeatureExtract.waveform_index(filter_data))\n",
    "                feature.append(FeatureExtract.peak_index(filter_data))\n",
    "                feature.append(FeatureExtract.impluse_factor(filter_data))\n",
    "                feature.append(FeatureExtract.tolerance_index(filter_data))\n",
    "                feature.append(FeatureExtract.skew_index(filter_data))\n",
    "                feature.append(FeatureExtract.kurt_index(filter_data))\n",
    "                # 10个频域特征\n",
    "                feature.append(FeatureExtract.fft_mean(filter_data))\n",
    "                feature.append(FeatureExtract.fft_var(filter_data))\n",
    "                feature.append(FeatureExtract.fft_std(filter_data))\n",
    "                feature.append(FeatureExtract.fft_entropy(filter_data))\n",
    "                feature.append(FeatureExtract.fft_energy(filter_data))\n",
    "                feature.append(FeatureExtract.fft_skew(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_mean(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_std(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_skew(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_kurt(filter_data))\n",
    "            # 如果行或者列闪烁则添加P300真值标签， 否则添加负标签\n",
    "            if table_event.cell(row+1, 1).value == chars[current_char][0] or table_event.cell(row+1, 1).value == chars[current_char][1]:\n",
    "                feature.append(table_event.cell(row+1, 1).value)\n",
    "            else:\n",
    "                feature.append(0)\n",
    "            classify_dataset.append(feature)\n",
    "print((np.array(classify_dataset)).shape)\n",
    "df = pd.DataFrame(classify_dataset)\n",
    "df.to_csv('../data/semi/s5_selected_train.csv')\n",
    "\n",
    "# 测试集\n",
    "char_test = ['M', 'F', '5', '2', 'I']\n",
    "ITER = 0\n",
    "for sheet in test_event.sheetnames:\n",
    "    # 完成前五个字符的sheet则退出\n",
    "    if ITER >=5:\n",
    "        break\n",
    "    # 当前字符\n",
    "    current_char = char_test[ITER]\n",
    "    ITER += 1\n",
    "    # print(current_char)\n",
    "    table_event = test_event[sheet]\n",
    "    table_data = test_data[sheet]\n",
    "    # 剔除bad通道电压值\n",
    "    for col_num in range(20):\n",
    "        if col_num+1 in optimal_channels:\n",
    "            pass\n",
    "        else:\n",
    "            table_data.delete_cols(col_num+1)\n",
    "            # print('delete ',col_num+1,' colum')\n",
    "    for row in range(test_event[sheet].max_row):\n",
    "        if table_event.cell(row+1, 1).value >= 1 and table_event.cell(row+1, 1).value <= 12:\n",
    "            # data.shape: 275,-100ms~1000ms时间窗口20个电压的均值\n",
    "            # feature: 26\n",
    "            feature = []\n",
    "            data = []\n",
    "            for i in range(len(optimal_channels)):\n",
    "                channel = []\n",
    "                for j in range(275):\n",
    "                    channel.append(table_data.cell(table_event.cell(row+1, 2).value-24+j, i+1).value)\n",
    "                data.append(channel)\n",
    "                # 带通滤波\n",
    "                # filter_data = scipy.signal.filtfilt(b, a, data[][i])\n",
    "                filter_data = data[i]\n",
    "                # 16个时域特征\n",
    "                feature.append(FeatureExtract.mean_fea(filter_data))\n",
    "                feature.append(FeatureExtract.rms_fea(filter_data))\n",
    "                feature.append(FeatureExtract.sr_fea(filter_data))\n",
    "                feature.append(FeatureExtract.am_fea(filter_data))\n",
    "                feature.append(FeatureExtract.skew_fea(filter_data))\n",
    "                feature.append(FeatureExtract.kurt_fea(filter_data))\n",
    "                feature.append(FeatureExtract.max_fea(filter_data))\n",
    "                feature.append(FeatureExtract.min_fea(filter_data))\n",
    "                feature.append(FeatureExtract.pp_fea(filter_data))\n",
    "                feature.append(FeatureExtract.var_fea(filter_data))\n",
    "                feature.append(FeatureExtract.waveform_index(filter_data))\n",
    "                feature.append(FeatureExtract.peak_index(filter_data))\n",
    "                feature.append(FeatureExtract.impluse_factor(filter_data))\n",
    "                feature.append(FeatureExtract.tolerance_index(filter_data))\n",
    "                feature.append(FeatureExtract.skew_index(filter_data))\n",
    "                feature.append(FeatureExtract.kurt_index(filter_data))\n",
    "                # 10个频域特征\n",
    "                feature.append(FeatureExtract.fft_mean(filter_data))\n",
    "                feature.append(FeatureExtract.fft_var(filter_data))\n",
    "                feature.append(FeatureExtract.fft_std(filter_data))\n",
    "                feature.append(FeatureExtract.fft_entropy(filter_data))\n",
    "                feature.append(FeatureExtract.fft_energy(filter_data))\n",
    "                feature.append(FeatureExtract.fft_skew(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_mean(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_std(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_skew(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_kurt(filter_data))\n",
    "            # 如果行或者列闪烁则添加P300真值标签， 否则添加负标签\n",
    "            if table_event.cell(row+1, 1).value == chars[current_char][0] or table_event.cell(row+1, 1).value == chars[current_char][1]:\n",
    "                feature.append(table_event.cell(row+1, 1).value)\n",
    "            else:\n",
    "                feature.append(0)\n",
    "            test_dataset.append(feature)\n",
    "print((np.array(test_dataset)).shape)\n",
    "df = pd.DataFrame(test_dataset)\n",
    "df.to_csv('../data/semi/s1_selected_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "dataset split:  960   240\n"
     ]
    }
   ],
   "source": [
    "# 加载上一步转换后数据集\n",
    "dataset_s1 = pd.read_csv('../data/semi/s1_selected_train.csv')\n",
    "dataset_s2 = pd.read_csv('../data/semi/s2_selected_train.csv')\n",
    "dataset_s3 = pd.read_csv('../data/semi/s3_selected_train.csv')\n",
    "dataset_s4 = pd.read_csv('../data/semi/s4_selected_train.csv')\n",
    "dataset_s5 = pd.read_csv('../data/semi/s5_selected_train.csv')\n",
    "dataset = np.concatenate((dataset_s1, dataset_s2, dataset_s3, dataset_s4, dataset_s5), axis=0)\n",
    "\n",
    "# 加载转换后测试集\n",
    "dataset_test_s1 = pd.read_csv('../data/semi/s1_selected_test.csv')\n",
    "dataset_test_s2 = pd.read_csv('../data/semi/s2_selected_test.csv')\n",
    "dataset_test_s3 = pd.read_csv('../data/semi/s3_selected_test.csv')\n",
    "dataset_test_s4 = pd.read_csv('../data/semi/s4_selected_test.csv')\n",
    "dataset_test_s5 = pd.read_csv('../data/semi/s5_selected_test.csv')\n",
    "\n",
    "# 随机删除过多的负样本,使正负样本1:1\n",
    "delete_num = 0\n",
    "while delete_num<2400:\n",
    "    index = np.random.choice(dataset.shape[0],1,replace=True)\n",
    "    # 只删负样本\n",
    "    if np.squeeze(dataset[index])[-1] == 0.0:\n",
    "        dataset = np.delete(dataset, index, axis=0)\n",
    "        delete_num += 1\n",
    "\n",
    "print(dataset.shape[0])\n",
    "data = dataset[:, 1:313]\n",
    "label = dataset[:, 313]\n",
    "for index in range(len(label)):\n",
    "    if label[index] != 0:\n",
    "        label[index] = 1\n",
    "\n",
    "# print(data.shape, len(label))\n",
    "\n",
    "# 为全监督划分数据集为训练集，验证集，比例 4:1\n",
    "data_train, data_eval, label_train, label_eval = train_test_split(data, label, test_size=0.2, random_state=1)\n",
    "print('dataset split: ', len(data_train), ' ',len(data_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.44      0.46       129\n",
      "         1.0       0.40      0.44      0.42       111\n",
      "\n",
      "    accuracy                           0.44       240\n",
      "   macro avg       0.44      0.44      0.44       240\n",
      "weighted avg       0.44      0.44      0.44       240\n",
      "\n",
      " Full Accuracy:  0.44166666666666665\n",
      "Training data size= 960 Labeld accuracy= 0.8635  , Unlabeled ratio= 0 ACC: 0.4417 AUC: 0.4417 F1-score: 0.4224\n",
      "[1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[0.5003286  0.5345744  0.5507247  0.75093114 0.69503945 0.50895983\n",
      " 0.58862984 0.53856957 0.56033146 0.543701   0.6369844  0.65161866\n",
      " 0.5006396  0.5199593  0.61605746 0.6466541  0.5041444  0.511393\n",
      " 0.69173    0.5015249  0.57006943 0.54639924 0.6639253  0.51520497\n",
      " 0.531404   0.68511486 0.56149507 0.72916126 0.671172   0.5858848\n",
      " 0.6818868  0.6721579  0.5223152  0.6693441  0.52725387 0.5558501\n",
      " 0.59101915 0.5182841  0.5293114  0.5282538  0.74540794 0.63183475\n",
      " 0.6692317  0.51150614 0.55787575 0.5783471  0.56436026 0.5158872\n",
      " 0.55487835 0.55534077 0.61248785 0.52243614 0.664179   0.6144058\n",
      " 0.53654695 0.52976805 0.55608845 0.5599953  0.6728068  0.5184889\n",
      " 0.6292373  0.5264951  0.56702816 0.7265165  0.5251235  0.711123\n",
      " 0.6689581  0.5872056  0.58470005 0.6431205  0.54084325 0.6191985\n",
      " 0.53933966 0.5209007  0.782494   0.552921   0.58567196 0.5021625\n",
      " 0.5913914  0.6306915  0.55779636 0.6088393  0.7396772  0.513422\n",
      " 0.53674036 0.7288116  0.6184742  0.6756365  0.5629743  0.5421127\n",
      " 0.55827284 0.54156405 0.6091038  0.64678884 0.60481924 0.6708999\n",
      " 0.5716954  0.597006   0.5275967  0.5768532  0.6775489  0.5239425\n",
      " 0.5042966  0.5556823  0.6262378  0.6386551  0.5989106  0.507581\n",
      " 0.56570965 0.555619   0.7188983  0.5317571  0.5294037  0.58167547\n",
      " 0.5374112  0.6103834  0.60858226 0.6024787  0.5581713  0.52042663\n",
      " 0.5197314  0.5702394  0.597097   0.57011026 0.5334495  0.53119874\n",
      " 0.54588705 0.5978924  0.5829183  0.50492865 0.5099637  0.5320393\n",
      " 0.61848354 0.6263499  0.6031848  0.578588   0.6249637  0.66086054\n",
      " 0.53478116 0.523452   0.67745197 0.55396366 0.5355274  0.5618046\n",
      " 0.5785434  0.54086095 0.51771337 0.52473634 0.590479   0.55565554\n",
      " 0.70010555 0.5986184  0.6346481  0.5795749  0.5037112  0.5409461\n",
      " 0.74887484 0.6437208  0.73624015 0.6599308  0.51229084 0.52012515\n",
      " 0.647446   0.6241404  0.6287421  0.6359079  0.55043197 0.5523175\n",
      " 0.64377064 0.6545262  0.5714636  0.660388   0.5464054  0.6936371\n",
      " 0.5873821  0.5331966  0.63100106 0.6118133  0.6304534  0.6113833\n",
      " 0.65142953 0.6337974  0.6451588  0.70168245 0.518687   0.5565829\n",
      " 0.5702069  0.5201552  0.6404149  0.55711746 0.5235282  0.5975131\n",
      " 0.5341898  0.51130533 0.5557444  0.60077655 0.591242   0.5744105\n",
      " 0.66597724 0.6078903  0.5826578  0.5495226  0.5043738  0.60377526\n",
      " 0.50132143 0.60475504 0.572303   0.5175588  0.5122552  0.56654644\n",
      " 0.5400421  0.5557748  0.5031445  0.6440419  0.6377746  0.51510006\n",
      " 0.6574964  0.5477823  0.5242132  0.6076361  0.65092033 0.63893354\n",
      " 0.5601443  0.54816324 0.583728   0.5197717  0.62362397 0.52424145\n",
      " 0.5466907  0.6692384  0.5974776  0.59113336 0.67407626 0.60949564\n",
      " 0.5657959  0.52520263 0.63304347 0.6399775  0.5620678  0.6150817\n",
      " 0.5168725  0.51480097 0.5121652  0.5573926  0.6026152  0.6179832\n",
      " 0.5776558  0.6106482  0.5814724  0.74493766 0.5382405  0.51429886\n",
      " 0.5343317  0.6300986  0.71586716 0.51238954 0.56799734 0.7261206\n",
      " 0.5226079  0.6420973  0.5338228  0.5271607  0.62529755 0.5405441\n",
      " 0.5175462  0.65771943 0.5802336  0.6997779  0.6055053  0.63255775\n",
      " 0.6202167  0.52761257 0.5036179  0.57185876 0.59978837 0.5586342\n",
      " 0.53323627 0.63958335 0.7033178  0.63217705 0.5052986  0.5130867\n",
      " 0.6464745  0.58324635 0.6562664  0.51608086 0.5674234  0.5057049\n",
      " 0.5547581  0.5378014  0.6191916  0.50398684 0.56648785 0.54850334\n",
      " 0.6663281  0.7808316  0.6409412  0.7292931  0.5777811  0.7021996\n",
      " 0.5940262  0.5125912  0.5467057  0.70879704 0.5276887  0.5866133\n",
      " 0.5023439  0.50476277 0.61087203 0.5877543  0.5616161  0.6085133\n",
      " 0.5320092  0.6133028  0.5792651  0.61981845 0.5937213  0.5422003\n",
      " 0.5634808  0.57456017 0.52690554 0.520869   0.52234125 0.59921205\n",
      " 0.5859801  0.5980267  0.52257884 0.51187605 0.5821991  0.5358065\n",
      " 0.5489471  0.52337646 0.5286444  0.58454025 0.5802278  0.6492285\n",
      " 0.5301498  0.50651973 0.5440469  0.545946   0.657577   0.6480595\n",
      " 0.57559633 0.5187129  0.5527852  0.6923064  0.67192686 0.5114207\n",
      " 0.6417758  0.60916483 0.5448435  0.6761598  0.56476694 0.55774844\n",
      " 0.61978996 0.725087   0.540113   0.540218   0.5015801  0.6005777\n",
      " 0.533855   0.5129066  0.58224654 0.65669954 0.5633997  0.56742084\n",
      " 0.540498   0.54548955 0.5478049  0.5680294  0.7412181  0.6381785\n",
      " 0.50671506 0.64828515 0.5045022  0.50388896 0.63565713 0.72339344\n",
      " 0.5628854  0.55803615 0.56908876 0.5567379  0.5093937  0.50908905\n",
      " 0.5316554  0.6643675  0.561075   0.517622   0.6213662  0.64291054\n",
      " 0.57868713 0.646566   0.6463593  0.51716536 0.513007   0.59739506\n",
      " 0.51240623 0.6795752  0.75699496 0.5579199  0.5002238  0.5741902\n",
      " 0.69334555 0.556927   0.5377224  0.5349974  0.60495317 0.593201\n",
      " 0.5979941  0.6178811  0.509301   0.53079474 0.5600715  0.54631615\n",
      " 0.6519357  0.51456654 0.6162083  0.5880347  0.6377991  0.62160945\n",
      " 0.7150508  0.53717345 0.66683817 0.5204837  0.5900023  0.5147253\n",
      " 0.57901466 0.61696064 0.53516257 0.52490866 0.6093351  0.60259193\n",
      " 0.564409   0.5530288  0.5035198  0.51351404 0.68345535 0.5243066\n",
      " 0.7164172  0.59396243 0.6997303  0.53616744 0.64241886 0.54117095\n",
      " 0.5953772  0.6955194  0.67116654 0.512398   0.6609725  0.5001335\n",
      " 0.58704644 0.54330873 0.50309426 0.59365594 0.5838299  0.5459328\n",
      " 0.64270395 0.50654644 0.53858423 0.50316143 0.65701467 0.593605\n",
      " 0.5793643  0.6176255  0.75395995 0.6065758  0.50239855 0.590035\n",
      " 0.5164313  0.5408005  0.5585022  0.5740441  0.6133934  0.5317144\n",
      " 0.5598204 ]\n",
      "iteration= 0 Training data size= 485 Labeld accuracy=:  0.9485  , Unlabeled ratio=:  0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 1 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 2 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 3 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 4 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 5 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 6 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 7 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration= 8 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 9 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "iteration= 10 Training data size= 485 Labeld accuracy= 0.9485  , Unlabeled ratio= 0.4948 ACC: 0.4583 AUC: 0.4660 F1-score: 0.4922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.36      0.42       129\n",
      "         1.0       0.43      0.57      0.49       111\n",
      "\n",
      "    accuracy                           0.46       240\n",
      "   macro avg       0.46      0.47      0.46       240\n",
      "weighted avg       0.47      0.46      0.45       240\n",
      "\n",
      "Semi Accuracy:  0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "# 自主训练半监督，全监督作baseline对照\n",
    "import xgboost\n",
    "\n",
    "model = xgboost.XGBClassifier(\n",
    "                            learning_rate=0.02,\n",
    "                            n_estimators=90,\n",
    "                            max_depth=4,\n",
    "                            min_child_weight=1,\n",
    "                            gamma=0,\n",
    "                            subsample=1,\n",
    "                            colsample_bytree=1,\n",
    "                            objective='binary:logistic',\n",
    "                            nthread=4,\n",
    "                            scale_pos_weight=1,\n",
    "                            seed=27)\n",
    "\n",
    "# 全监督\n",
    "clf_full = model.fit(data_train, label_train)\n",
    "pred_full = clf_full.predict(data_eval)\n",
    "print(classification_report(label_eval, pred_full))\n",
    "print(\" Full Accuracy: \", accuracy_score(label_eval,pred_full))\n",
    "\n",
    "# 自学习半监督\n",
    "# 定义一个无标签样本占训练集比例,去掉其标签\n",
    "ratio = 0.5\n",
    "rng = np.random.RandomState(10)\n",
    "\n",
    "semi_label = np.copy(label_train)\n",
    "semi_label[rng.rand(len(label_train)) < ratio] = -1\n",
    "\n",
    "unlabeledX = data_train[semi_label == -1, :]\n",
    "YTrue = label_train[semi_label == -1]\n",
    "\n",
    "idx = np.where(semi_label != -1)[0]\n",
    "labeledX = data_train[idx, :]\n",
    "labeledY = semi_label[idx]\n",
    "\n",
    "# 全监督\n",
    "clf = model.fit(data_train, label_train)\n",
    "score = accuracy_score(label_train, clf.predict(data_train))\n",
    "test_score = accuracy_score(label_eval, clf.predict(data_eval))   # 测试集准确率\n",
    "auc_score = roc_auc_score(label_eval, clf.predict(data_eval))\n",
    "f1 = f1_score(label_eval, clf.predict(data_eval))\n",
    "print(\"Training data size=\", len(label_train), \"Labeld accuracy= %.4f\" % score, \" , Unlabeled ratio=\", 0,\n",
    "      \"ACC: %.4f\" % test_score, 'AUC: %.4f' % auc_score, 'F1-score: %.4f' % f1)\n",
    "\n",
    "# 半监督\n",
    "clf = model.fit(labeledX, labeledY)\n",
    "unlabeledY = clf.predict(unlabeledX)\n",
    "unlabeledProb = clf.predict_proba(unlabeledX).max(axis=1)  # 预测为0和1的置信度，取大的\n",
    "ratioInitial = 1 - (len(labeledY) / len(label_train))\n",
    "score = accuracy_score(labeledY, clf.predict(labeledX))\n",
    "test_score = accuracy_score(label_eval, clf.predict(data_eval))\n",
    "auc_score = roc_auc_score(label_eval, clf.predict(data_eval))\n",
    "f1 = f1_score(label_eval, clf.predict(data_eval))\n",
    "print(\"iteration=\",0, \"Training data size=\", len(labeledY), \"Labeld accuracy=:  %.4f\" % score, \" , Unlabeled ratio=:  %.4f\" % ratioInitial, \"ACC: %.4f\" % test_score, 'AUC: %.4f' % auc_score, 'F1-score: %.4f' % f1)\n",
    "\n",
    "max_iter = 960\n",
    "# 分类置信度阈值\n",
    "probThreshold = 0.8\n",
    "\n",
    "unlabeledXOrg = np.copy(unlabeledX)\n",
    "YTrueOrg = np.copy(YTrue)\n",
    "\n",
    "rr = []\n",
    "it = []\n",
    "\n",
    "i = 0\n",
    "repeat = 1\n",
    "\n",
    "log_Labeld_accuracy1 = []\n",
    "log_Labeld_accuracy2 = []\n",
    "log_Labeld_accuracy3 = []\n",
    "\n",
    "while (i < max_iter and score > 0.01 and repeat<=10):\n",
    "\n",
    "    lastscore = score\n",
    "    ratio = 1 - (len(labeledY) / len(label_train))\n",
    "\n",
    "    rr.append(ratio)\n",
    "    it.append(i)\n",
    "\n",
    "    labelidx = np.where(unlabeledProb > probThreshold)[0]\n",
    "    unlabelidx = np.where(unlabeledProb <= probThreshold)[0]\n",
    "\n",
    "    labeledX = np.vstack((labeledX, unlabeledX[labelidx, :]))  # 按照行顺序把数组给堆叠起来\n",
    "    labeledY = np.hstack((labeledY, unlabeledY[labelidx]))\n",
    "    unlabeledX = unlabeledX[unlabelidx, :]\n",
    "    YTrue = label_train[unlabelidx]\n",
    "\n",
    "    clf = model.fit(labeledX, labeledY)\n",
    "    score = accuracy_score(labeledY, clf.predict(labeledX))\n",
    "    test_score = accuracy_score(label_eval, clf.predict(data_eval))\n",
    "    auc_score = roc_auc_score(label_eval, clf.predict(data_eval))\n",
    "    f1 = f1_score(label_eval, clf.predict(data_eval))\n",
    "    Labeld accuracy.append(score)\n",
    "    print(\"iteration=\",i+1, \"Training data size=\", len(labeledY), \"Labeld accuracy= %.4f\" % score, \" , Unlabeled ratio= %.4f\" % ratio, \"ACC: %.4f\" % test_score, 'AUC: %.4f' % auc_score, 'F1-score: %.4f' % f1)\n",
    "\n",
    "    unlabeledY = clf.predict(unlabeledX)\n",
    "    unlabeledProb = clf.predict_proba(unlabeledX).max(axis=1)\n",
    "\n",
    "    i += 1\n",
    "    if lastscore == score:\n",
    "        repeat += 1\n",
    "    else:\n",
    "        repeat = 1\n",
    "        \n",
    "\n",
    "\n",
    "# 保存模型\n",
    "file_semi = open('model/semi.pickle', 'wb')\n",
    "clf_semi_model = pickle.dump(clf, file_semi)\n",
    "# 验证集评估\n",
    "pred_semi = clf.predict(data_eval)\n",
    "print(classification_report(label_eval, pred_semi))\n",
    "print(\"Semi Accuracy: \", accuracy_score(label_eval,pred_semi))\n",
    "\n",
    "# 测试集前五个字符数据上评估\n",
    "pred_test = clf.predict(data_eval)\n",
    "print(classification_report(label_eval, pred_test))\n",
    "print(\"Semi Accuracy: \", accuracy_score(label_eval,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 12, 521)\n"
     ]
    }
   ],
   "source": [
    "# 针对测试集中char13~17检验方法\n",
    "\n",
    "# 测试数据加载\n",
    "raw_test_data = openpyxl.load_workbook(u'/home/chris/predict_code/lyft/bci/data/S1/S1_test_data.xlsx')\n",
    "raw_test_event = openpyxl.load_workbook(u'/home/chris/predict_code/lyft/bci/data/S1/S1_test_event.xlsx')\n",
    "\n",
    "# 测试数据预处理，特征提取, 5*5*12*521\n",
    "# (即前5个有标签字符，每个五轮，每轮12次闪烁，20个通道，每个通道26个特征，共520特征,外加一个字符矩阵行列标识符)\n",
    "# 标签即M、F、5、2、I\n",
    "test_label = [113, 106, 131, 128, 109]\n",
    "test_data = []\n",
    "\n",
    "# 带通滤波器上下界\n",
    "freq_min, freq_max = 1, 30\n",
    "# 调用8阶带通滤波器\n",
    "# b, a = scipy.signal.butter(8, [0.02,0.8], 'bandpass')\n",
    "\n",
    "for sheet in raw_test_data.sheetnames:\n",
    "    # 取sheet数据\n",
    "    table_event = raw_test_event[sheet]\n",
    "    table_data = raw_test_data[sheet]\n",
    "    \n",
    "    # 转换后数据,5轮次P300脑电处理后数据\n",
    "    iter = 0 # 轮次数\n",
    "    count = 0 # 计数\n",
    "    char_data = [] # 多轮数据, 5*12*521\n",
    "    iter_data = [] # 一轮数据, 12*521\n",
    "    for row in range(raw_test_event[sheet].max_row):\n",
    "        if table_event.cell(row+1, 1).value >= 1 and table_event.cell(row+1, 1).value <= 12:\n",
    "            # data.shape: 275*20,-100ms~1000ms时间窗口\n",
    "            # feature: 520\n",
    "            feature = []\n",
    "            data = []\n",
    "            \n",
    "            if count % 12 == 0:\n",
    "                iter += 1\n",
    "                count = 0\n",
    "                char_data.append(iter_data)\n",
    "                iter_data.clear()\n",
    "            \n",
    "            for i in range(20):\n",
    "                channel = []\n",
    "                for j in range(275):\n",
    "                    channel.append(table_data.cell(table_event.cell(row+1, 2).value-24+j, i+1).value)\n",
    "                data.append(channel)\n",
    "            for i in range(20):\n",
    "                # 带通滤波\n",
    "                # filter_data = scipy.signal.filtfilt(b, a, data[i])\n",
    "                filter_data = data[i]\n",
    "                # 16个时域特征\n",
    "                feature.append(FeatureExtract.mean_fea(filter_data))\n",
    "                feature.append(FeatureExtract.rms_fea(filter_data))\n",
    "                feature.append(FeatureExtract.sr_fea(filter_data))\n",
    "                feature.append(FeatureExtract.am_fea(filter_data))\n",
    "                feature.append(FeatureExtract.skew_fea(filter_data))\n",
    "                feature.append(FeatureExtract.kurt_fea(filter_data))\n",
    "                feature.append(FeatureExtract.max_fea(filter_data))\n",
    "                feature.append(FeatureExtract.min_fea(filter_data))\n",
    "                feature.append(FeatureExtract.pp_fea(filter_data))\n",
    "                feature.append(FeatureExtract.var_fea(filter_data))\n",
    "                feature.append(FeatureExtract.waveform_index(filter_data))\n",
    "                feature.append(FeatureExtract.peak_index(filter_data))\n",
    "                feature.append(FeatureExtract.impluse_factor(filter_data))\n",
    "                feature.append(FeatureExtract.tolerance_index(filter_data))\n",
    "                feature.append(FeatureExtract.skew_index(filter_data))\n",
    "                feature.append(FeatureExtract.kurt_index(filter_data))\n",
    "                # 10个频域特征\n",
    "                feature.append(FeatureExtract.fft_mean(filter_data))\n",
    "                feature.append(FeatureExtract.fft_var(filter_data))\n",
    "                feature.append(FeatureExtract.fft_std(filter_data))\n",
    "                feature.append(FeatureExtract.fft_entropy(filter_data))\n",
    "                feature.append(FeatureExtract.fft_energy(filter_data))\n",
    "                feature.append(FeatureExtract.fft_skew(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_mean(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_std(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_skew(filter_data))\n",
    "                feature.append(FeatureExtract.fft_shape_kurt(filter_data))\n",
    "                # 字符矩阵行列标识符\n",
    "            feature.append(table_event.cell(row+1, 1).value)\n",
    "            iter_data.append(feature)\n",
    "            count += 1\n",
    "    test_data.append(char_data)     \n",
    "print((np.array(test_data)).shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Workbook' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-19dbb327fd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclf_p300\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 轮询后5个字符数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# size:5, 12, 521\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcurrent_char_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Workbook' has no len()"
     ]
    }
   ],
   "source": [
    "# P300二分类器模型加载,输出后5个字符\n",
    "answer = []\n",
    "with open('model/semi.pickle', 'rb') as fr:\n",
    "    clf_p300 = pickle.load(fr)\n",
    "    # 轮询后5个字符数据\n",
    "    for i in range(len(test_data)):\n",
    "        # size:5, 12, 521\n",
    "        current_char_data = np.array(test_data[i])\n",
    "        char_prob = []\n",
    "        for j in range(len(current_char_data)):\n",
    "            # size: 12, 521\n",
    "            curr_iter_data = current_char_data[j]\n",
    "            # 12次闪烁后脑电含P300波的概率， 12×(prob, 对应row或colum号)\n",
    "            p300_prob = []\n",
    "            for k in range(len(curr_iter_data)):\n",
    "                prob_pred = (np.squeeze(clf_p300.predict_proba(np.expand_dims(curr_iter_data[k][0:-2], 0))))[0]\n",
    "                # 行列标识符和对应该行列闪烁后有无P300的概率组成元组\n",
    "                p300_prob.append((prob_pred, curr_iter_data[k][-1]))\n",
    "            char_prob.append(p300_prob)\n",
    "        # print((np.array(char_prob)))\n",
    "        # P300二分类检测完成，求字符\n",
    "        prob = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] # 初始各行或列闪烁后有无P300概率\n",
    "        for a in range(len(char_prob)):\n",
    "            p300_iter = char_prob[a]\n",
    "            # 多轮加权\n",
    "            for b in range(len(p300_iter)):\n",
    "                prob[int(p300_iter[b][1]-1)] += p300_iter[b][0]\n",
    "            for index in range(len(prob)):\n",
    "                prob[index] = prob[index]/5.0\n",
    "        # print(prob)\n",
    "        # 求出对应行列标识符\n",
    "        char_row = np.argmax(prob[0:6])\n",
    "        char_col = np.argmax(prob[6:])\n",
    "        # 基于行列标识符，按值找键查字符矩阵标识符字典\n",
    "        answer.append([k for k,v in chars.items() if v==(char_row+1, char_col+7)])\n",
    "        print((char_row+1, char_col+7), answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
